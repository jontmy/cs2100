\section{Pipelining}
\textbf{Pipelining} increases workload throughput, but is \textit{rate limited} by the
slowest stage in the pipeline, and \textit{stalled} by dependencies between stages.

Each execution stage in the MIPS datapath is a \textbf{pipeline stage} which takes 1 clock cycle:

\begin{enumerate}
    \keyitem*{\code{fetch}}{requires the instruction memory}
    \keyitem*{\code{decode}}{involves the register file}
    \keyitem*{\code{execute}}{involves the ALU}
    \keyitem*{\code{memory}}{requires data memory}
    \keyitem*{\code{writeback}}{involves the register file}
\end{enumerate}

Data required for each stage is stored separately in \textbf{4 pipeline registers}:

\begin{enumerate}
    \keyitem*{\code{IF/ID}}{between \code{fetch} and \code{decode}}
    \keyitem*{\code{ID/EX}}{between \code{decode} and \code{execute}}
    \keyitem*{\code{EX/MEM}}{between \code{execute} and \code{memory}}
    \keyitem*{\code{MEM/WB}}{between \code{memory} and \code{writeback}}
\end{enumerate}

\begin{tblr}{
    colspec = {lXX},
    row{1} = {font=\bfseries},
}
    \toprule
    register & receives & supplies \\
    \midrule
    \code{IF/ID} & {\code{Instruction[PC]}, \\ \code{PC + 4}} & {\code{RR1} and \code{RR2}, \\ 16-bit \code{offset}, \\ \code{PC + 4}, \\ \code{WR}} \\
    \code{ID/EX} & {\code{RD1} and \code{RD2}, \\ 32-bit \code{imm}, \\ \code{PC + 4}, \\ \code{WR}} & {\code{RD1} and \code{RD2}, \\ 32-bit \code{imm}, \\ \code{PC + 4}, \\ \code{WR}} \\
    \code{EX/MEM} & {\code{PC + 4 + 4 * imm}, \\ ALU result, \\ \code{isZero?}, \\ \code{RD2}, \\ \code{WR}} & {\code{PC + 4 + 4 * imm}, \\ ALU result, \\ \code{isZero?}, \\ \code{RD2}, \\ \code{WR}} \\
    \code{MEM/WB} & {ALU result, \\ memory data read, \\ \code{WR}} & \code{WR} \\
    \bottomrule
\end{tblr}

\begin{defn}{control signals}
    All control signals are generated in the \code{decode} stage and propagated to their
    respective pipeline stages.

    \begin{itemize}
        \keyitem*{\code{execute}}{\code{RegDst, ALUSrc, ALUOp}}
        \keyitem*{\code{memory}}{\code{MemRead, MemWrite, Branch}}
        \keyitem*{\code{writeback}}{\code{MemToReg, RegWrite}}
    \end{itemize}
\end{defn}

\subsection{Performance}

\begin{defn}{single-cycle processor}
    Each instruction takes 1 clock cycle to execute.

    The \textbf{cycle time} $CT_{seq}$ is the longest time taken to execute any single instruction:

    \( CT_{seq} = \max \left( \sum_{k=1}^{N} T_k \right) \)

    where $N$ is the number of stages and $T_k$ is the time taken to execute an operation in stage $k$.

    The \textbf{execution time} $ET_{seq}$ depends on the number of instructions $I$:
    
    \( ET_{seq} = CT_{seq} \cdot I \)
\end{defn}

\begin{defn}{multi-cycle processor}
    Each \textit{stage} takes 1 clock cycle to execute.

    The \textbf{cycle time} $CT_{multi}$ is the longest time taken to execute any single stage.

    The \textbf{execution time} $ET_{multi}$ depends on the number of instructions $I$ and the average
    number of instructions per instruction $CPI_{avg}$:
    
    \( ET_{multi} = CT_{multi} \cdot I \cdot CPI_{avg} \)
\end{defn}

\begin{defn}{pipelined processor}
    The \textbf{cycle time} $CT_{pipelined}$ incurs a pipelining overhead $T_d$:

    \( CT_{pipelined} = \max \left( T_k \right) + T_d \)

    where $T_k$ is the time taken to execute an operation in stage $k$.

    The \textbf{execution time} $ET_{pipelined}$ depends on the number of instructions $I$ and stages $N$:
    
    \( ET_{pipelined} = CT_{pipelined} \times (I + N - 1) \)
\end{defn}

In an \textbf{ideal pipeline}:
\begin{itemize*}
    \item every stage takes the same amount of time: \\[0.25em] \( \sum_{k=1}^{N} T_k = N \cdot T_1 \)
    \item there is no pipeline overhead: \\[0.25em] \( T_d = 0 \)
    \item the number of instructions is much larger than the number of stages: \\[0.25em] \( I >> N \)
\end{itemize*}

This results in a \textbf{ideal speedup} by $N$:

\( \frac{ET_{seq}}{ET_{pipelined}} = \frac{I \cdot N \cdot T_1}{(I + N - 1) \cdot T_1} \approx \frac{I \cdot N \cdot T_1}{I \cdot T_1} = N \)


\subsection{Hazards}

\textbf{Pipeline hazards} are problems that prevent an instruction immediately
after a previous instruction.

\textbf{Structural hazards} are caused by simultaneous use of the same register file,
memory, or ALU by multiple instructions.

\begin{defn}{resolving structural hazards}
    a) stall the execution by one or more cycles.

    b) split the memory into \code{Data} and \code{Instruction}.

    c) write to the register file in the first half of a cycle,
    and read in the second half --- allowed as register access is fast.
\end{defn}

\textbf{Data hazards} are caused by \textbf{read-after-write (RAW) dependencies} between instructions,
where the result of an instruction is read by a subsequent instruction.

This can lead to \textbf{stale results} if the result is not written to the register file in time.

\begin{defn}{resolving RAW data hazards --- forwarding}
    Suppose sequential instructions \code{B}, \code{C}, and \code{D} each have a RAW dependency on
    instruction \code{A}.

    With \textbf{forwarding}, the result of \code{A} is computed in the \code{execute} stage, and
    is fed into the \code{execute} stage of \code{B} and \code{C}, bypassing the register file.

    \code{B} receives the result from the pipeline register \code{EX/MEM}.
    \code{C} receives the result from \code{MEM/WB}.

    Because writing and reading to the register file in two different halves of the same clock cycle,
    instruction \code{D} can read the result from the register file.
\end{defn}

\begin{defn}{resolving loading data hazards --- stalling}
    Suppose instruction \code{A} reads data from memory, and \code{B} and \code{C} are dependent on
    this data.
    
    Because \code{A} produces this data in the \code{memory} stage only after it is needed by
    the \code{execute} stage of B, no data can be forwarded yet.

    Consequently, \code{B} has to \textbf{stall} the pipeline until its \code{execute} stage
    can receive forwarded data from \code{MEM/WB} from \code{A}.

    If \code{B} is the next instruction after \code{A}, then the stall is 1 clock cycle long.

    Because writing and reading to the register file in two different halves of the same clock cycle,
    instruction \code{C} can read the result from the register file.
\end{defn}

\textbf{Control hazards} are caused by a change in program flow.

Branching decisions are made in the \code{memory} stage, which is too late as the next instructions will
be partially executed.

\begin{defn}{resolving control hazards --- stalling}
    The \textbf{branch decision} is known in the \code{memory} stage, so we can stall for 3 clock cycles
    and then \code{fetch} the next instruction.
\end{defn}

\begin{defn}{resolving control hazards --- early branch resolution}
    Moving the branch decision to the \code{execute} stage allows reduces the stall duration to 1 clock cycle.

    If a value in the branch instruction is \textit{computed} in the preceding instruction, the stall duration is only
    reduced to 2 clock cycles.

    If a value in the branch instruction is \textit{loaded} in the preceding instruction, the stall duration
    remains at 3 clock cycles.
\end{defn}

\begin{defn}{resolving control hazards --- branch prediction}
    Assume all branches are not taken, no stall required.
    Flush the succeeding instruction from the pipeline if the branch \textit{is} taken.

    Flushing wastes 3 clock cycles without early branch resolution.
    With early branch resolution, it wastes the same number of clock cycles as stalling would.
\end{defn}

\begin{defn}{resolving control hazards --- delayed branching}
    Instructions which precede the branching instruction and are executed regardless of the
    branch decision are re-ordered to execute \textit{after} the branch instruction.

    The MIPS processor has 1 of these \textbf{branch-delay slots}.

    If no such instruction can be found, the branch instruction is delayed by 1 clock cycle
    via a \code{nop}.
\end{defn}
